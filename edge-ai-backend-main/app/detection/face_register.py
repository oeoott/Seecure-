# app/detection/face_register.py

import cv2
import numpy as np
import os
from typing import Optional, Tuple

# --- ì§€ì—° ë¡œë”©ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ---
_onnx_session = None
_face_mesh = None

def get_onnx_session():
    """ONNX ì„¸ì…˜ì„ ì§€ì—° ë¡œë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _onnx_session
    if _onnx_session is None:
        print("[INFO] Loading ONNX model for face registration...")
        import onnxruntime as ort
        YOLO_MODEL_PATH = "app/models/yolov8n-face.onnx"
        _onnx_session = ort.InferenceSession(YOLO_MODEL_PATH)
    return _onnx_session

def get_face_mesh():
    """MediaPipe Face Meshë¥¼ ì§€ì—° ë¡œë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _face_mesh
    if _face_mesh is None:
        print("[INFO] Loading MediaPipe Face Mesh for face registration...")
        import mediapipe as mp
        mp_face_mesh = mp.solutions.face_mesh
        _face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)
    return _face_mesh

def preprocess_for_onnx(img, input_size=640):
    img_resized = cv2.resize(img, (input_size, input_size))
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    img_norm = img_rgb.astype(np.float32) / 255.0
    img_transposed = np.transpose(img_norm, (2, 0, 1))
    img_input = np.expand_dims(img_transposed, axis=0)
    return img_input, img.shape[:2]

def detect_face_bbox(onnx_session, frame: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
    """ONNX ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ì—ì„œ ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì–¼êµ´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    input_tensor, original_shape = preprocess_for_onnx(frame)
    ort_inputs = {onnx_session.get_inputs()[0].name: input_tensor}
    outputs = onnx_session.run(None, ort_inputs)[0]

    boxes = outputs[0]
    h, w = original_shape
    best_box = None
    max_conf = 0.5  # ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’

    for box in boxes:
        conf = box[4]
        if conf > max_conf:
            max_conf = conf
            x_center, y_center, bw, bh = box[0:4]
            x1 = int((x_center - bw / 2) * w / 640)
            y1 = int((y_center - bh / 2) * h / 640)
            x2 = int((x_center + bw / 2) * w / 640)
            y2 = int((y_center + bh / 2) * h / 640)
            best_box = (x1, y1, x2, y2)
            
    return best_box

def register_user_face(image_bytes: bytes, user_id: str):
    """
    ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ ë°›ì•„ ì–¼êµ´ì„ ë“±ë¡í•˜ê³ , ì–¼êµ´ê³¼ ëˆˆ ì¢Œí‘œë¥¼ .npy íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        onnx_session = get_onnx_session()
        face_mesh = get_face_mesh()

        frame = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
        if frame is None:
            raise ValueError("Could not decode image.")

        face_bbox = detect_face_bbox(onnx_session, frame)

        if not face_bbox:
            raise ValueError("ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë°ì€ ê³³ì—ì„œ ì •ë©´ì„ ë³´ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        x1, y1, x2, y2 = face_bbox
        face_roi = frame[y1:y2, x1:x2]

        # --- ğŸ”½ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤ ---
        # ì˜ë¼ë‚¸ ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
        if face_roi.size == 0:
            raise ValueError("ì–¼êµ´ ì˜ì—­ì„ ì˜ë¼ë‚´ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        resized_face = cv2.resize(face_roi, (100, 100))

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = face_mesh.process(rgb)
        if result.multi_face_landmarks:
            landmarks = result.multi_face_landmarks[0].landmark
            h, w, _ = frame.shape
            left_iris_idx, right_iris_idx = 473, 468 # MediaPipe v0.9+
            
            left = np.array([landmarks[left_iris_idx].x * w, landmarks[left_iris_idx].y * h])
            right = np.array([landmarks[right_iris_idx].x * w, landmarks[right_iris_idx].y * h])
            eye_center = ((left + right) / 2).astype(np.float32)

            # --- ì‚¬ìš©ìë³„ ë°ì´í„° ì €ì¥ì„ ìœ„í•´ ê²½ë¡œ ìˆ˜ì • ---
            user_data_dir = f"app/models/{user_id}"
            os.makedirs(user_data_dir, exist_ok=True)
            
            np.save(os.path.join(user_data_dir, "user_face.npy"), resized_face)
            np.save(os.path.join(user_data_dir, "user_eye_pos.npy"), eye_center)

            print(f"[ì™„ë£Œ] ì‚¬ìš©ì ID '{user_id}'ì˜ ì–¼êµ´ê³¼ ì‹œì„  ì¢Œí‘œ ì €ì¥ë¨.")
        else:
            raise ValueError("ì–¼êµ´ì˜ ìƒì„¸ ì¢Œí‘œ(ëˆˆ ìœ„ì¹˜)ë¥¼ ì°¾ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"Error during face registration: {e}")
        # API ë¼ìš°í„°ì—ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        raise e
